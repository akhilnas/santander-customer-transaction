{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Data Manipulation Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Model & Helper Libraries\n",
    "import os\n",
    "import io\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "# Plotting Tools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sagemaker Unique Libraries\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "from sagemaker.inputs import TrainingInput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Configure Boto3 Clients and Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = boto3.Session().region_name\n",
    "smclient = boto3.Session().client(\"sagemaker\")\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "bucket = \"sagemaker-santander\"\n",
    "\n",
    "print(f'AWS Region name : {region},\\nSession : {smclient},\\nRole : {role}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Files in Input Training Directory\n",
    "s3client = boto3.client('s3') # S3 Client\n",
    "subfolder = 'input-data' # Subfolder\n",
    "contents = s3client.list_objects(Bucket=bucket, Prefix=subfolder)['Contents']\n",
    "for f in contents:\n",
    "    print(f['Key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'input-data/train.csv'\n",
    "response = s3client.get_object(Bucket=bucket, Key=input_file)\n",
    "df = pd.read_csv(io.BytesIO(response['Body'].read()))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_colums = [c for c in df.columns if c not in ['ID_code','target']]\n",
    "X = df.loc[:, var_colums]\n",
    "y = df.loc[:, 'target']\n",
    "\n",
    "# We are performing a 80-20 split for Training and Validation\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\n",
    "X_train.shape, X_valid.shape, y_train.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct Train and Validation Dataframes\n",
    "pd.concat([y_train, X_train], axis=1).to_csv(\n",
    "    \"train.csv\", index=False, header=False\n",
    ")\n",
    "pd.concat([y_valid, X_valid], axis=1).to_csv(\n",
    "    \"validation.csv\", index=False, header=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the files to S3\n",
    "boto3.Session().resource(\"s3\").Bucket(bucket).Object(\n",
    "    \"train/train.csv\"\n",
    ").upload_file(\"train.csv\")\n",
    "boto3.Session().resource(\"s3\").Bucket(bucket).Object(\n",
    "    \"validation/validation.csv\"\n",
    ").upload_file(\"validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "\n",
    "container = sagemaker.image_uris.retrieve(\"xgboost\", boto3.Session().region_name, \"latest\")\n",
    "\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    output_path=\"s3://{}/output\".format(bucket),\n",
    "    sagemaker_session=sess,\n",
    ")\n",
    "\n",
    "xgb.set_hyperparameters(\n",
    "    eval_metric=\"auc\",\n",
    "    objective=\"binary:logistic\",\n",
    "    num_round=100,\n",
    "    rate_drop=0.3,\n",
    "    tweedie_variance_power=1.4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Hyper-paramter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {\n",
    "    \"max_depth\": IntegerParameter(1, 4),\n",
    "}\n",
    "\n",
    "objective_metric_name = \"validation:auc\"\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    xgb, objective_metric_name, hyperparameter_ranges, max_jobs=2, max_parallel_jobs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_train = sagemaker.inputs.TrainingInput(\n",
    "    s3_data=\"s3://{}/train\".format(bucket),\n",
    "    content_type=\"csv\",\n",
    "\n",
    ")\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(\n",
    "    s3_data=\"s3://{}/validation\".format(bucket), \n",
    "    content_type=\"csv\",\n",
    "\n",
    ")\n",
    "\n",
    "tuner.fit({\"train\": s3_input_train, \"validation\": s3_input_validation}, include_cls_metadata=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Examine Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_job_name = 'xgboost-210923-2339'\n",
    "tuner = sagemaker.HyperparameterTuningJobAnalytics(tuning_job_name)\n",
    "\n",
    "full_df = tuner.dataframe()\n",
    "\n",
    "if len(full_df) > 0:\n",
    "    df = full_df[full_df[\"FinalObjectiveValue\"] > -float(\"inf\")]\n",
    "    if len(df) > 0:\n",
    "        df = df.sort_values(\"FinalObjectiveValue\", ascending=False)\n",
    "        print(\"Number of training jobs with valid objective: %d\" % len(df))\n",
    "        print({\"lowest\": min(df[\"FinalObjectiveValue\"]), \"highest\": max(df[\"FinalObjectiveValue\"])})\n",
    "        pd.set_option(\"display.max_colwidth\", -1)  # Don't truncate TrainingJobName\n",
    "    else:\n",
    "        print(\"No training jobs have reported valid results yet.\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bokeh\n",
    "import bokeh.io\n",
    "\n",
    "bokeh.io.output_notebook()\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.models import HoverTool\n",
    "\n",
    "\n",
    "class HoverHelper:\n",
    "    def __init__(self, tuning_analytics):\n",
    "        self.tuner = tuning_analytics\n",
    "\n",
    "    def hovertool(self):\n",
    "        tooltips = [\n",
    "            (\"FinalObjectiveValue\", \"@FinalObjectiveValue\"),\n",
    "            (\"TrainingJobName\", \"@TrainingJobName\"),\n",
    "        ]\n",
    "        for k in self.tuner.tuning_ranges.keys():\n",
    "            tooltips.append((k, \"@{%s}\" % k))\n",
    "\n",
    "        ht = HoverTool(tooltips=tooltips)\n",
    "        return ht\n",
    "\n",
    "    def tools(self, standard_tools=\"pan,crosshair,wheel_zoom,zoom_in,zoom_out,undo,reset\"):\n",
    "        return [self.hovertool(), standard_tools]\n",
    "\n",
    "\n",
    "hover = HoverHelper(tuner)\n",
    "\n",
    "p = figure(plot_width=900, plot_height=400, tools=hover.tools(), x_axis_type=\"datetime\")\n",
    "p.circle(source=df, x=\"TrainingStartTime\", y=\"FinalObjectiveValue\")\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_job_result = smclient.describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuning_job_name\n",
    ")\n",
    "objective_name = tuning_job_result['HyperParameterTuningJobConfig']['HyperParameterTuningJobObjective'][\"MetricName\"]\n",
    "\n",
    "ranges = tuner.tuning_ranges\n",
    "figures = []\n",
    "for hp_name, hp_range in ranges.items():\n",
    "    categorical_args = {}\n",
    "    if hp_range.get(\"Values\"):\n",
    "        # This is marked as categorical.  Check if all options are actually numbers.\n",
    "        def is_num(x):\n",
    "            try:\n",
    "                float(x)\n",
    "                return 1\n",
    "            except:\n",
    "                return 0\n",
    "\n",
    "        vals = hp_range[\"Values\"]\n",
    "        if sum([is_num(x) for x in vals]) == len(vals):\n",
    "            # Bokeh has issues plotting a \"categorical\" range that's actually numeric, so plot as numeric\n",
    "            print(\"Hyperparameter %s is tuned as categorical, but all values are numeric\" % hp_name)\n",
    "        else:\n",
    "            # Set up extra options for plotting categoricals.  A bit tricky when they're actually numbers.\n",
    "            categorical_args[\"x_range\"] = vals\n",
    "\n",
    "    # Now plot it\n",
    "    p = figure(\n",
    "        plot_width=500,\n",
    "        plot_height=500,\n",
    "        title=\"Objective vs %s\" % hp_name,\n",
    "        tools=hover.tools(),\n",
    "        x_axis_label=hp_name,\n",
    "        y_axis_label=objective_name,\n",
    "        **categorical_args,\n",
    "    )\n",
    "    p.circle(source=df, x=hp_name, y=\"FinalObjectiveValue\")\n",
    "    figures.append(p)\n",
    "show(bokeh.layouts.Column(*figures))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sagemaker.analytics.HyperparameterTuningJobAnalytics(tuning_job_name)\n",
    "results_df = results.dataframe()\n",
    "best_training_job_summary = results.description()[\"BestTrainingJob\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_training_job_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach to an existing hyperparameter tuning job.\n",
    "tuning_job_details = smclient.describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuning_job_name\n",
    ")\n",
    "xgb_tuner = HyperparameterTuner.attach(\n",
    "    tuning_job_name,\n",
    "    job_details=tuning_job_details,\n",
    "    sagemaker_session=sagemaker.Session(),\n",
    "    estimator_cls=None,\n",
    ")\n",
    "\n",
    "# Get the best XGBoost training job name from the HPO job\n",
    "xgb_best_training_job = xgb_tuner.best_training_job()\n",
    "print(xgb_best_training_job)\n",
    "# Attach estimator to the best training job name\n",
    "best_estimator = sagemaker.estimator.Estimator.attach(xgb_best_training_job)\n",
    "\n",
    "# Create model to be passed to the inference pipeline\n",
    "best_model = sagemaker.model.Model(\n",
    "    model_data=best_estimator.model_data,\n",
    "    role=sagemaker.get_execution_role(),\n",
    "    image_uri=best_estimator.image_uri,\n",
    ")\n",
    "\n",
    "predictor = best_model.deploy(initial_instance_count=1, instance_type=\"ml.m5.large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
